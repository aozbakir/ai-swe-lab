[
  {
    "question": "What is the main purpose of the EU AI Act?",
    "answer": "The Regulation’s purpose is to improve the functioning of the internal market and promote the uptake of human‑centric and trustworthy AI, while ensuring protection of health, safety, fundamental rights, democracy, the rule of law and environmental protection against harmful effects of AI systems."
  },
  {
    "question": "Which document is the AI Act adopted as?",
    "answer": "It is adopted as Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024."
  },
  {
    "question": "What kinds of AI practices are prohibited under the AI Act?",
    "answer": "The Act prohibits certain AI practices. For example, placing on the market or using an AI system that deploys subliminal manipulation, or exploits vulnerabilities of a specific group, is disallowed."
  },
  {
    "question": "What is the territorial scope of the Act?",
    "answer": "The Act applies to providers, users, importers and distributors of AI systems in the Union as well as those in third countries if the output produced by the system is used in the Union."
  },
  {
    "question": "How are AI systems classified under the Act in terms of risk?",
    "answer": "The Regulation divides AI systems into risk categories, namely unacceptable risk (banned), high‑risk (strict obligations), limited/minimal risk (lighter obligations), and it covers general‑purpose AI models too."
  },
  {
    "question": "What is the definition of an 'AI system' according to the Act?",
    "answer": "An 'AI system' is defined as a machine‑based system that is designed to operate with varying levels of autonomy and that may exhibit adaptive or autonomous behaviour."
  },
  {
    "question": "When did the AI Act enter into force?",
    "answer": "The Regulation was published in the Official Journal 12 July 2024 and entered into force on 1 August 2024."
  },
  {
    "question": "What are the obligations for providers of high‑risk AI systems?",
    "answer": "Providers of high‑risk AI systems must ensure conformity assessment, compliance with transparency, documentation, robustness, accuracy and data governance obligations before placing the system on the market or putting it into service."
  },
  {
    "question": "Are open‑source AI models exempt from the Act?",
    "answer": "The Act does not entirely exempt open‑source models; rather, its obligations depend on risk categories — even open‑source may fall under certain obligations if high‑risk or used in a certain way."
  },
  {
    "question": "What is the significance of the AI Act globally?",
    "answer": "The Act is considered the first comprehensive legal framework for AI worldwide, positioning Europe as a leader in trustworthy AI regulation and setting standards that may have global spill‑over effects."
  }
]
